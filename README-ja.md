# markdown-crawler

[English](README.md) | [繁體中文](README-zhTW.md) | [日本語](README-ja.md)

AI読解に最適化されたウェブクローラーツールで、ウェブコンテンツを構造化されたMarkdown形式に変換します。インテリジェントなアルゴリズムでノイズを除去し、コアコンテンツを抽出して、AIモデルの理解と処理に適したクリーンなテキストデータを生成します。特徴的なのは、ウェブサイトの関連ページ（現在のページとそのすべてのサブディレクトリを含む）を単一のYAMLファイルに統合し、明確に構造化されたMarkdownコンテンツを生成できることです。

## なぜAI読解に適しているのか？

- 🧠 広告やナビゲーションバーなどのノイズを除去し、メインコンテンツをインテリジェントに抽出
- 🎯 記事の論理構造と意味関係を保持
- 📋 AIが解析しやすい標準化されたMarkdown形式に変換
- 🔄 特殊文字とエンコーディングを自動処理
- 📊 すべてのページをYAML形式で統合し、バッチ処理が容易

## 主な機能

- 🚀 fetchとcheerioを使用した効率的なウェブクローリングで、最新のウェブページをサポート
- 📝 MozillaのReadabilityアルゴリズムによるインテリジェントなコンテンツ抽出
- ✨ 不要なスタイルとノイズを除去し、構造化されたMarkdown形式に自動変換
- 🎨 GitHub Flavored Markdown (GFM)をサポートし、重要な書式を保持
- 💻 コードブロックのシンタックスハイライトをサポートし、技術文書の可読性を維持
- 🔗 関連ページを自動的にクロールし、単一ファイルに統合
- 🧹 依存関係を最小限に最適化し、軽量で高速な動作を確保
- ⚡ 処理パイプラインの最適化による大幅なパフォーマンス向上
- 📄 より洗練されたMarkdown出力と適切なリンク処理

## データ統合の利点

- 📚 対象URLとそのすべてのサブディレクトリページを自動クロール
- 🗂️ すべてのページコンテンツを単一のYAMLファイルに統合
- 📖 各ページのタイトルとコンテンツの完全性を維持
- 🎯 人間の読解とAI処理の両方に適したMarkdown形式を生成
- 🔍 大量の関連コンテンツの迅速な閲覧と検索が可能

## 使用方法

```bash
# 基本的な使用法
npx markdown-crawler <URL> <出力ファイル名>

# 例：ウェブサイトをクロールしoutput.yamlとして保存
npx markdown-crawler https://example.com output

# スペースを含むURLには二重引用符を使用
npx markdown-crawler "https://example.com/my page" output

# 出力ファイルには自動的に.yaml拡張子が追加されます
# 結果は現在の作業ディレクトリに保存されます
```

## 出力形式

ツールはすべての関連ページを構造化されたYAML形式に統合します：
```yaml
- title: "メインページタイトル"
  url: "https://example.com/"
  content: |
    # メインページコンテンツ
    ここにメインページの本文が入ります...

- title: "サブページ1タイトル"
  url: "https://example.com/subpage1"
  content: |
    # サブページ1コンテンツ
    ここにサブページ1の本文が入ります...

- title: "サブページ2タイトル"
  url: "https://example.com/subpage2"
  content: |
    # サブページ2コンテンツ
    ここにサブページ2の本文が入ります...
```

特徴：
- 各ページのタイトルとメインコンテンツを自動抽出
- 参照用に各ページの元のURLを含む
- コンテンツの階層構造とフォーマットを維持
- 不要なスタイルとスクリプトを除去
- 適切なリンク形式を持つ、クリーンで読みやすいMarkdownを生成
- チェックボックスなどのMarkdown要素を正確に保持
- 人間の読解とAIモデル処理の両方に適している

## システム要件

- Node.js >= 16.0.0
- npmまたはyarnパッケージマネージャー

## ライセンス

このプロジェクトはMITライセンスの下で提供されています - 詳細は[LICENSE](LICENSE)ファイルをご覧ください。
